{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7651bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5203e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the env variables\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd26094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State variable\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our LLM (llama-3.1-8b-instant) from Groq for faster inference\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f8e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat node in our graph, that communicates to the LLM\n",
    "\n",
    "def chat_node (state: ChatState) -> ChatState:\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403c2e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ChatState)\n",
    "\n",
    "# in RAM memory for out chatbot\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Nodes in our graph\n",
    "graph.add_node(\"chat_node\", chat_node)\n",
    "\n",
    "# Edges connecting the nodes\n",
    "graph.add_edge(START, \"chat_node\")\n",
    "graph.add_edge(\"chat_node\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = graph.compile(checkpointer=checkpointer)\n",
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a22bd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  hey\n",
      "AI:  Hey Rahul. Feeling a bit chatty today? Want to keep talking about fitness or move on to something else?\n",
      "\n",
      "User:  i am sad\n",
      "AI:  I'm so sorry to hear that, Rahul. It's okay to feel sad sometimes, and I'm here to listen if you want to talk about what's on your mind.\n",
      "\n",
      "If you're comfortable, can you tell me a bit more about what's making you feel sad? Sometimes sharing your feelings with someone can help you feel a little better.\n",
      "\n",
      "If you're not ready to talk about it, that's okay too. I can suggest some things that might help you feel a bit better, like taking a deep breath, going for a walk, or doing something you enjoy.\n",
      "\n",
      "You're not alone, Rahul. I'm here to support you.\n",
      "\n",
      "User:  \n",
      "AI:  It can be hard to put into words what's going on. Take your time, and when you're ready, feel free to talk about it or just listen to some calming words.\n",
      "\n",
      "Remember, you're strong and capable, and things might seem dark right now, but they can get better. Sometimes, all we need is someone to listen and offer a comforting presence.\n",
      "\n",
      "If you need some distractions, I can tell you a funny joke, or we can play a game, or I can suggest some relaxing activities.\n",
      "\n",
      "Whatever you need, Rahul, I'm here for you.\n",
      "\n",
      "User:  bye\n"
     ]
    }
   ],
   "source": [
    "# Client Side\n",
    "\n",
    "thread_id = \"1\"\n",
    "\n",
    "while True:\n",
    "    user_message = input(\"Type Here: \")\n",
    "    print(\"User: \",user_message)\n",
    "    \n",
    "    if user_message.strip().lower() in [\"end\", \"exit\", \"bye\", \"sakyo\"]:\n",
    "        break\n",
    "    \n",
    "    # Config variable that manages the persistence\n",
    "    \n",
    "    config = {\"configurable\" : {\"thread_id\" : thread_id}}\n",
    "    \n",
    "    response = chatbot.invoke({\"messages\" : [HumanMessage(content=user_message)]}, config=config)\n",
    "    \n",
    "    print(\"AI: \",response[\"messages\"][-1].content)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
